{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haw River Levels\n",
    "Data feed from [USGS REST API](https://waterservices.usgs.gov/rest/IV-Service.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet as lf\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://waterservices.usgs.gov/nwis/iv/?format=json' + \\\n",
    "        '&sites=02096960,02096500' + \\\n",
    "        '&startDT=2018-09-17' + \\\n",
    "        '&endDT=2018-09-19' + \\\n",
    "        '&parameterCd=00060,00065' + \\\n",
    "        '&siteStatus=all'\n",
    "\n",
    "def get_location_data(location):\n",
    "    '''Extracts location data from a timeSeries data array.\n",
    "    Returns a dictionary of site data and a dataframe of\n",
    "    the metric for that location.'''\n",
    "    \n",
    "    # Time series array to time series dataframe\n",
    "    metrics = pd.DataFrame.from_records(location['values'][0]['value'])\n",
    "    \n",
    "    # Set data types\n",
    "    metrics['value'] = metrics['value'].astype('float64')\n",
    "    metrics['dateTime'] = metrics['dateTime'].astype('datetime64')\n",
    "    \n",
    "    # Add time limits to meta data\n",
    "    start = metrics['dateTime'].min()\n",
    "    end = metrics['dateTime'].max()\n",
    "    \n",
    "    # Set value name to metric description\n",
    "    description = location['variable']['variableDescription']\n",
    "    description = description.replace(' ','_').replace(',','').lower()\n",
    "    metrics.rename(columns={'value':description}, inplace=True)\n",
    "    \n",
    "    # Set index to timescale\n",
    "    metrics.set_index('dateTime', inplace=True)\n",
    "    \n",
    "    # Change array in qualifiers to string\n",
    "    if type(metrics.qualifiers[0]) == list:\n",
    "        \n",
    "        metrics['status'] = [i[0] for i in metrics.qualifiers]\n",
    "    \n",
    "    # Dictionary of metadata with metrics dataframe\n",
    "    source = location['sourceInfo']\n",
    "    geo_info = source['geoLocation']['geogLocation']\n",
    "    \n",
    "    site_data = {\n",
    "        'site_name':source['siteName'].title().replace('Nc','NC'),\n",
    "        'site_code':source['siteCode'][0]['value'],\n",
    "        'network':source['siteCode'][0]['network'],\n",
    "        'projection':geo_info['srs'],\n",
    "        'latitude':geo_info['latitude'],\n",
    "        'longitude':geo_info['longitude'],\n",
    "        'coordinates':(geo_info['latitude'],\n",
    "                       geo_info['longitude']),\n",
    "        'measurement':location['variable']['variableName'],\n",
    "        'description':description,\n",
    "        'start_datetime': start,\n",
    "        'end_datetime': end,\n",
    "        'metrics':metrics,\n",
    "                }\n",
    "    \n",
    "    \n",
    "    return (site_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Main Loop\n",
    "\n",
    "data = requests.get(url)\n",
    "raw_data = data.json()\n",
    "time_series = raw_data['value']['timeSeries']\n",
    "\n",
    "dataset = {}\n",
    "for location in time_series:\n",
    "    site_data = get_location_data(location) \n",
    "    #print(site_data['metrics'])\n",
    "    unique_name = site_data['site_name'] + \\\n",
    "    '-' + \\\n",
    "    site_data['description']\n",
    "    key_name = unique_name.lower().replace(' ','_').replace(',','')\n",
    "    dataset[key_name] = site_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n",
      "match\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['haw_river_at_haw_river_nc', 'haw_river_near_bynum_nc'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_location = [None,]\n",
    "prev_key = None\n",
    "location_datasets = {}\n",
    "for key in dataset.keys():\n",
    "    # Extract the location portion of the name\n",
    "    location = key.split('-')[0]\n",
    "    \n",
    "    # Match against previous location\n",
    "    if prev_location[0] == location:\n",
    "        current = dataset[key]['metrics']\n",
    "        \n",
    "        # Inner join the datasets, drop redundant columns\n",
    "        merged = pd.merge(dataset[key]['metrics'].drop(\n",
    "                        columns=['qualifiers',]),\n",
    "                  dataset[prev_key]['metrics'].drop(\n",
    "                          columns=['qualifiers', 'status']),\n",
    "                  left_index = True,\n",
    "                  right_index = True)\n",
    "        \n",
    "        # Add the combined data to the datasets\n",
    "        location_datasets[location] = merged\n",
    "    prev_location = [location,]\n",
    "    prev_key = key\n",
    "location_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage_height_feet</th>\n",
       "      <th>discharge_cubic_feet_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>288.000000</td>\n",
       "      <td>288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.303854</td>\n",
       "      <td>29906.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.480894</td>\n",
       "      <td>16720.101271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.520000</td>\n",
       "      <td>5230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.545000</td>\n",
       "      <td>10850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.960000</td>\n",
       "      <td>31800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.502500</td>\n",
       "      <td>45600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.620000</td>\n",
       "      <td>51900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gage_height_feet  discharge_cubic_feet_per_second\n",
       "count        288.000000                       288.000000\n",
       "mean          13.303854                     29906.736111\n",
       "std            3.480894                     16720.101271\n",
       "min            7.520000                      5230.000000\n",
       "25%            9.545000                     10850.000000\n",
       "50%           13.960000                     31800.000000\n",
       "75%           16.502500                     45600.000000\n",
       "max           17.620000                     51900.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in location_datasets.keys():\n",
    "    p = location_datasets[key]\n",
    "    \n",
    "p.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
